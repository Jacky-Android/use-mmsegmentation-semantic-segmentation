{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U openmim\n!mim install mmcv-full","metadata":{"scrolled":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/open-mmlab/mmsegmentation.git","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /home/rongjian/yolov7-main/wandb\n!git clone https://github.com/open-mmlab/mmcv.git\n%cd mmcv\n!pip install -r requirements.txt\n","metadata":{"scrolled":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /home/rongjian/yolov7-main/wandb/mmsegmentation\n!pip install -v -e .","metadata":{"scrolled":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /home/rongjian/yolov7-main/wandb\n%mkdir datas\n%mkdir datas/ann\n%mkdir datas/ann/training\n%mkdir datas/ann/validation\n%mkdir datas/images\n%mkdir datas/images/training\n%mkdir datas/images/validation","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom shutil import copy\nfrom sys import exit\nimport tqdm\npath = \"/home/rongjian/yolov7-main/wandb/dataset/semantic_drone_dataset/original_images\" #文件夹目录\npath_map = \"/home/rongjian/yolov7-main/wandb/dataset/semantic_drone_dataset/label_images_semantic\"\nfiles= os.listdir(path) #得到文件夹下的所有文件名称\n\nfor i in range(len(files)):\n    if i<360:\n        copy(path+'/'+files[i], '/home/rongjian/yolov7-main/wandb/datas/images/training')\n        copy(path_map+'/'+files[i][:-4]+'.png', '/home/rongjian/yolov7-main/wandb/datas/ann/training')\n    elif 359<i<400:\n        copy(path+'/'+files[i], '/home/rongjian/yolov7-main/wandb/datas/images/validation')\n        copy(path_map+'/'+files[i][:-4]+'.png', '/home/rongjian/yolov7-main/wandb/datas/ann/validation')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /home/rongjian/yolov7-main/wandb/mmsegmentation","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile configs/_base_/models/danet_r50-d8.py\nnorm_cfg = dict(type='SyncBN', requires_grad=True)\nmodel = dict(\n    type='EncoderDecoder',\n    pretrained='open-mmlab://resnet50_v1c',\n    backbone=dict(\n        type='ResNetV1c',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        dilations=(1, 1, 2, 4),\n        strides=(1, 2, 1, 1),\n        norm_cfg=norm_cfg,\n        norm_eval=False,\n        style='pytorch',\n        contract_dilation=True),\n    decode_head=dict(\n        type='DAHead',\n        in_channels=2048,\n        in_index=3,\n        channels=512,\n        pam_channels=64,\n        dropout_ratio=0.1,\n        num_classes=23,\n        norm_cfg=norm_cfg,\n        align_corners=False,\n        loss_decode=dict(\n            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n    auxiliary_head=dict(\n        type='FCNHead',\n        in_channels=1024,\n        in_index=2,\n        channels=256,\n        num_convs=1,\n        concat_input=False,\n        dropout_ratio=0.1,\n        num_classes=23,\n        norm_cfg=norm_cfg,\n        align_corners=False,\n        loss_decode=dict(\n            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n    # model training and testing settings\n    train_cfg=dict(),\n    test_cfg=dict(mode='whole'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile mmseg/datasets/my_dataset.py\nimport mmcv\nfrom mmcv.utils import print_log\n\nfrom ..utils import get_root_logger\nfrom .builder import DATASETS\nfrom .custom import CustomDataset\n\n\n@DATASETS.register_module()\n\nclass Mydataset(CustomDataset):\n   \n    CLASSES = ('unlabeled', 'paved-area', 'dirt', 'grass', 'gravel', 'water',\n               'rocks', 'pool', 'vegetation', 'roof', 'wall', 'window', 'door', 'fence', \n               'fence-pole', 'person', 'dog', 'car', 'bicycle', 'tree', 'bald-tree', 'ar-marker', \n               'obstacle')\n\n    PALETTE = [[0, 0, 0], [128, 64, 128], [130, 76, 0], [0, 102, 0], [112, 103, 87], [28, 42, 168], \n               [48, 41, 30], [0, 50, 89], [107, 142, 35], [70, 70, 70], [102, 102, 156], [254, 228, 12], \n               [254, 148, 12], [190, 153, 153], [153, 153, 153], [255, 22, 96], [102, 51, 0], [9, 143, 150], \n               [119, 11, 32], [51, 51, 0], [190, 250, 190], [112, 150, 146], [2, 135, 115]]\n\n\n    def __init__(self, **kwargs):\n        super(Mydataset, self).__init__(\n            img_suffix='.jpg',\n            seg_map_suffix='.png',\n            ignore_index=255,\n            **kwargs)\n        assert self.file_client.exists(self.img_dir)\n\n    def load_annotations(self,\n                         img_dir,\n                         img_suffix,\n                         ann_dir,\n                         seg_map_suffix=None,\n                         split=None):\n        \n\n        img_infos = []\n        if split is not None:\n            with open(split) as f:\n                for line in f:\n                    name = line.strip()\n                    img_info = dict(filename=name + img_suffix)\n                    if ann_dir is not None:\n                        ann_name = name \n                        seg_map = ann_name + seg_map_suffix\n                        img_info['ann'] = dict(seg_map=seg_map)\n                    img_infos.append(img_info)\n        else:\n            for img in mmcv.scandir(img_dir, img_suffix, recursive=True):\n                img_info = dict(filename=img)\n                if ann_dir is not None:\n                    seg_img = img\n                    seg_map = seg_img.replace(\n                        img_suffix,  seg_map_suffix)\n                    img_info['ann'] = dict(seg_map=seg_map)\n                img_infos.append(img_info)\n\n        print_log(f'Loaded {len(img_infos)} images', logger=get_root_logger())\n        return img_infos","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile configs/_base_/datasets/my_dataset.py\ndataset_type = 'Mydataset' #上一步中你定义的数据集的名字\ndata_root = '/home/rongjian/yolov7-main/wandb/datas' #数据集存储路径\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ncrop_size = (768,768)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations'),\n    dict(type='Resize', img_scale=(768,768), ratio_range=(0.5, 2.0)),\n    dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.75),\n    dict(type='RandomFlip', prob=0.5),\n    dict(type='PhotoMetricDistortion'),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size=crop_size, pad_val=0, seg_pad_val=255),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(768,768),\n        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img']),\n        ])\n]\ndata = dict(\n    samples_per_gpu=5,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        data_root=data_root,\n        img_dir='images/training', #训练图像路径\n        ann_dir='ann/training', #训练mask路径\n        pipeline=train_pipeline),\n    val=dict(\n        type=dataset_type,\n        data_root=data_root,\n        img_dir='images/validation',  #验证图像路径\n        ann_dir='ann/validation',  #验证mask路径\n        pipeline=test_pipeline),\n    #我的数据集没有测试集，和验证集用同一路径，问题不大\n    test=dict(\n        type=dataset_type,\n        data_root=data_root,\n        img_dir='images/validation',  #测试图像路径\n        ann_dir='ann/validation',  #测试mask路径\n        pipeline=test_pipeline))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile mmseg/datasets/__init__.py\nfrom .ade import ADE20KDataset\nfrom .builder import DATASETS, PIPELINES, build_dataloader, build_dataset\nfrom .chase_db1 import ChaseDB1Dataset\nfrom .cityscapes import CityscapesDataset\nfrom .coco_stuff import COCOStuffDataset\nfrom .custom import CustomDataset\nfrom .dark_zurich import DarkZurichDataset\nfrom .dataset_wrappers import (ConcatDataset, MultiImageMixDataset,\n                               RepeatDataset)\nfrom .drive import DRIVEDataset\nfrom .hrf import HRFDataset\nfrom .isaid import iSAIDDataset\nfrom .isprs import ISPRSDataset\nfrom .loveda import LoveDADataset\nfrom .night_driving import NightDrivingDataset\nfrom .pascal_context import PascalContextDataset, PascalContextDataset59\nfrom .potsdam import PotsdamDataset\nfrom .stare import STAREDataset\nfrom .voc import PascalVOCDataset\nimport sys\nsys.path.append('..')\nfrom .my_dataset import Mydataset\n__all__ = [\n    'CustomDataset', 'build_dataloader', 'ConcatDataset', 'RepeatDataset',\n    'DATASETS', 'build_dataset', 'PIPELINES', 'CityscapesDataset',\n    'PascalVOCDataset', 'ADE20KDataset', 'PascalContextDataset',\n    'PascalContextDataset59', 'ChaseDB1Dataset', 'DRIVEDataset', 'HRFDataset',\n    'STAREDataset', 'DarkZurichDataset', 'NightDrivingDataset',\n    'COCOStuffDataset', 'LoveDADataset', 'MultiImageMixDataset',\n    'iSAIDDataset', 'ISPRSDataset', 'PotsdamDataset','Mydataset'\n]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile configs/_base_/schedules/schedule_20k.py\noptimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\noptimizer_config = dict()\n# learning policy\nlr_config = dict(policy='poly', power=0.9, min_lr=1e-4, by_epoch=False)\nrunner = dict(type='EpochBasedRunner', max_epochs=100) #按epoch的方式进行迭代\ncheckpoint_config = dict(by_epoch=True, interval=50) #每多少次迭代保存一次模型\nevaluation = dict(interval=5, metric='mIoU')  # 每多少次迭代计算一次指标\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile configs/pspnet/pspnet_r50-d8_512x512_160k_ade20k.py \n_base_ = [\n    '../_base_/models/danet_r50-d8.py',\n    '../_base_/datasets/my_dataset.py', '../_base_/default_runtime.py',\n    '../_base_/schedules/schedule_20k.py'\n]\nmodel = dict(\n    decode_head=dict(num_classes=23), auxiliary_head=dict(num_classes=23))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python tools/train.py configs/pspnet/pspnet_r50-d8_512x512_160k_ade20k.py  ","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python tools/test.py configs/pspnet/pspnet_r50-d8_512x512_160k_ade20k.py work_dirs/pspnet_r50-d8_512x512_160k_ade20k/latest.pth --opacity 1 --eval mIoU --show-dir out","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\npath = '/home/rongjian/yolov7-main/wandb/datas/images/validation'\nfiles = os.listdir(path)\n# 使用matplotlib展示多张图片\nnum = len(files)\nj = 0\nwhile j<len(files):\n    \n    for i in range(0,3):\n        if i==2:\n            img = cv2.imread('/home/rongjian/yolov7-main/wandb/mmsegmentation/out'+'/'+files[j][:-4]+'.jpg')\n            title=\"predict\"\n        #行，列，索引\n            plt.subplot(1,3,i+1)\n        #plt.figure(figsize=(2, 2))\n            plt.imshow(img)\n            plt.title(title,fontsize=8)\n            plt.xticks([])\n            plt.yticks([])\n    \n        elif i==1:\n            img = cv2.imread('/home/rongjian/yolov7-main/wandb/RGB_color_image_masks/RGB_color_image_masks'+'/'+files[j][:-4]+'.png')\n            title=\"ground ture\"\n        #行，列，索引\n            plt.subplot(1,3,i+1)\n            #plt.figure(figsize=(2,2))\n            plt.imshow(img)\n            plt.title(title,fontsize=8)\n            plt.xticks([])\n            plt.yticks([])\n        elif i==0:\n            img = cv2.imread('/home/rongjian/yolov7-main/wandb/datas/images/validation'+'/'+files[j][:-4]+'.jpg')\n            title=\"image\"\n        #行，列，索引\n            plt.subplot(1,3,i+1)\n            #plt.figure(figsize=(2, 2))\n            plt.imshow(img)\n            plt.title(title,fontsize=8)\n            plt.xticks([])\n            plt.yticks([])   \n    plt.show()\n    j = j+1\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}